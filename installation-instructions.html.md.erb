---
title: Deploying to Tanzu Application Service
owner: TAS Releng
---

This topic describes how to deploy Tanzu Application Service.

<%= partial 'evaluation_only' %>

<%= partial 'limitation_notes' %>

## <a id='prerequisites'></a> Prerequisites

### vSphere Requirements

In general, follow the guidance provided by the [Enterprise PKS vSphere Prerequisites and Resource Requirements](https://docs.pivotal.io/pks/1-6/vsphere-requirements.html).

At a minimum, one must have enough resources in their vSphere foundation to support deploying:

* the Pivotal Ops Manager, BOSH director, Enterprise PKS service VMs, as specified in the [Enterprise PKS vSphere Resource Requirements](https://docs.pivotal.io/pks/1-6/vsphere-requirements.html#resources)
* an additional 6 VMs, with at least 2CPU, and 7.5GB memory per VM, for the Kubernetes master and worker nodes


### CLIs

Retrieve the following CLIs to provision a PKS cluster on vSphere and to deploy Tanzu Application Service 

* [pks cli](https://docs.pivotal.io/pks/1-6/installing-pks-cli.html)
* [kubectl cli](https://docs.pivotal.io/pks/1-6/installing-kubectl-cli.html)
* [k14s tools](https://k14s.io)


### Deployment Artifacts

Download the desired deployment artifact from the [VMware Tanzu Network product page](https://network.pivotal.io/products/pas-for-kubernetes)

> Note: one only needs to download the Tanzu Application Service tarball. A manifest with the Image References is already present in the tarball and is programmatically consumed by the deployment script, which is also contained within the tarball.


## <a id='provision'></a> Provision an Enterprise PKS cluster for Tanzu Application Service

> Note: this installation document assumes that one has already deployed Enterprise PKS onto the foundation. 
> 
> If this is not the case, please follow the Enterprise PKS installation instructions provided at:
> 
> 1. [Installing Enterprise PKS on vSphere](https://docs.pivotal.io/pks/1-6/installing-pks-vsphere.html)
> 1. [Configuring PKS API Load Balancer](https://docs.pivotal.io/pks/1-6/vsphere-configure-pks-api.html)

### Provision the Cluster

1. [Log in to the PKS CLI](https://docs.pivotal.io/pks/1-6/login.html#login)

2. Provision a cluster that satisfies the minimum resource requirements:

	> ⌛ Provisioning a cluster will take approximately 30 minutes.

	```bash	
	pks create-cluster "${CLUSTER_NAME}" \
	  --external-hostname "${EXTERNAL_HOSTNAME}" \
	  --plan "${PLAN_NAME}"
	```
	
	Where:
	* `${CLUSTER_NAME}` is the desired name of the cluster to be provisioned
	* `${EXTERNAL_HOSTANME}` is the desired fully qualified domain name (FQDN) or IP address that will point to the Master Node(s) of the Kubernetes cluster
	* `${PLAN_NAME}` is the name of a desired plan specified during the Enterprise PKS Cluster Tile installation. This plan must satisfy the minimum vSphere resource requirments.

	For example:
	
	```bash
	pks create-cluster tas-cluster \
      --external-hostname "tas-cluster.example.com" \
      --plan tanzu-application-service
	```

3. Create DNS record pointing to the newly created master node.
	
	First retreive the IP(s) of the Master Node(s) using the PKS cli:
	
	```bash
	pks cluster "${CLUSTER_NAME}"
	```
	
	For example:
	
	```bash
	$ pks cluster tas-cluster

	Name:                     tas-cluster
	Plan Name:                tanzu-application-service
	UUID:                     aaaa1234-bb56-cc78-dd90-eeffgghhii10
	Last Action:              CREATE
	Last Action State:        succeeded
	Last Action Description:  Instance provisioning completed
	Kubernetes Master Host:   tas-cluster.example.com
	Kubernetes Master Port:   8443
	Worker Instances:         5
	Kubernetes Master IP(s):  1.2.3.4, 5.6.7.8
	```

	Then create an `A` record from the `${EXTERNAL_HOSTNAME}` pointing to the IP(s):
	
	```
	"${EXTERNAL_HOSTNAME}" → KUBERNETES_MASTER_IPs
	```
	
	For example:
	
	```
	tas-cluster.example.com → 1.2.3.4, 5.6.7.8
	```

4. Retrieve the credentials and target the cluster with `kubectl`:

	```bash
	pks get-credentials "${CLUSTER_NAME}"
	
	kubectl cluster-info
	```
	
	For example:
	
   ```
	$ pks get-credentials tas-cluster
    
   Fetching credentials for cluster tas-cluster.
   Context set for cluster tas-cluster.
   
   You can now switch between clusters by using:
   $kubectl config use-context <cluster-name>
    
   
   $ kubectl cluster-info
   
   Kubernetes master is running at https://tas-cluster.example.com:8443
   CoreDNS is running at https://tas-cluster.example.com:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
    
   To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
    ```

## <a id='deploy'></a> Deploying Tanzu Application Service

### Unpack the deployment artifact

1. Unpack the deployment artifact using `tar`, for example:

   ```bash
   mkdir -p tanzau-application-service
   tar xvf ~/Downloads/tanzu-application-service.0.0.0-build.000.tar -C tanzu-application-service
   ```

### Generate deployment values

#### Option 1 - Manually 

1. Copy the sample deployment values file from the unpacked artifact

   ```bash
   cp tanzu-application-service/config/cf-for-k8s/sample-cf-install-values.yml deployment-values.yml
   ```
   
1. Open `deployment-values.yml` in an editor and replace the `system_domain` and `app_domain` with the desired domain address(es).
1. Generate certificates for the desired `system_domain`, and `app_domain` with the SAN `*.cf-system.svc.cluster.local` 
1. Replace the associated `crt`, `key` and `ca` fields in the `deployment-values.yml`

#### Option 2 (Preferred, but optional) - Using the `bosh` cli

> Note: This method is **optional** and relies on the functionality of `bosh interpolate` to easily generate the values. One must also have the `bosh` cli locally to proceed with this method.
> 
> Please also keep in mind that this script will generate self-signed certifcates on deployment.

There is another script contained within the unpacked artifact that can automatically generate deployment values. 

1. Simply feed the script the desired domain for the foundation and redirect the output of the command for use later when deploying:

   ```bash
   tanzu-application-service/config/cf-for-k8s/hack/generate-values.sh "${SYSTEM_DOMAIN}" > deployment-values.yml
   ```
   
   For example:
   
   ```bash
   tanzu-application-service/config/cf-for-k8s/hack/generate-values.sh "tas.example.com" > deployment-values.yml
   ```


### Deploy

1. Deploy Tanzu Application Service

	> ⌛ Deploying takes approximately 10-15 minutes.

	```bash
	export YTT_TAS_registry__server="registry.pivotal.io"
	export YTT_TAS_registry__username="..."
	export YTT_TAS_registry__password="..."
	
	cd tanzu-application-service
	bin/install-tas.sh /path/to/deployment-values.yml
	```
	
	Where:
	
	* `YTT_TAS_registry__server` is the FQDN of the Tanzu Network Registry, e.g. `registry.pivotal.io`.
	* `YTT_TAS_registry__username` is your Tanzu Network username
	* `YTT_TAS_registry__password` is your Tanzu Network password

### Post-Deployment Configuration

1. Deploy the load balancing pods onto the Kubernetes cluster for ingress traffic.

   ```bash
   kubectl apply --filename config/cf-k8s-networking/config/no-loadbalancer/node-to-ingressgateway-daemonset.yaml
   ```

3. Create a DNS record pointing to the external IPs of the Kubernetes worker nodes to finish ingress conectivity.
	
	First retreive the IPs of the worker nodes using the `kubectl` cli:
	
	```bash
	kubectl get nodes --output='wide'
	```
	
	For example:
	
	```bash
	$ kubectl get nodes --output='wide'
   NAME                                   STATUS   ROLES    AGE     VERSION   INTERNAL-IP    EXTERNAL-IP    OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
   5e329c31-f1d7-4548-936b-3a58d4b166d3   Ready    <none>   5h49m   v1.15.5   10.85.87.133   10.85.87.133   Ubuntu 16.04.6 LTS   4.15.0-76-generic   docker://18.9.9
   a6ad3f07-787c-4d90-b8e1-032be34e9d7f   Ready    <none>   5h43m   v1.15.5   10.85.87.134   10.85.87.134   Ubuntu 16.04.6 LTS   4.15.0-76-generic   docker://18.9.9
   a8eb78a2-e3b4-4d8a-8c32-67bf0e13c0bf   Ready    <none>   5h43m   v1.15.5   10.85.87.135   10.85.87.135   Ubuntu 16.04.6 LTS   4.15.0-76-generic   docker://18.9.9
   af7dc8da-a7b0-4cf2-a940-c9248168e609   Ready    <none>   5h43m   v1.15.5   10.85.87.136   10.85.87.136   Ubuntu 16.04.6 LTS   4.15.0-76-generic   docker://18.9.9
   cc6ef11f-e253-4553-9cb0-bebc7d958f64   Ready    <none>   5h42m   v1.15.5   10.85.87.137   10.85.87.137   Ubuntu 16.04.6 LTS   4.15.0-76-generic   docker://18.9.9
	```

	Then create a wildcard `A` record pointing to the IPs:
	
	```
	*.system_domain → EXTERNAL-IPs
	```
	
	For example:
	
	```
	*.tas.example.com      →   10.85.87.133
	                           10.85.87.134
	                           10.85.87.135
	                           10.85.87.136
	                           10.85.87.137
	```



### (Optional) Post-Deploy Validation
1. Follow the [`cf-for-k8s` instructions](https://github.com/cloudfoundry/cf-for-k8s/blob/master/docs/deploy.md#validate-the-deployment) to validate the deployment.
